{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80293e36-2c9c-4aba-9e2e-b1a0b2324d76",
   "metadata": {},
   "source": [
    "Implementing the \"hack\" described in the paper  \"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing\" (https://arxiv.org/abs/2406.08464) to generate an instruction dataset with the format:\n",
    "\n",
    "{\"instruction\": What type of cloud is typically associated with thunderstorms?,<br>\n",
    "\"output\": The type of cloud typically associated with thunderstorms is cumulonimbus.}\n",
    "\n",
    "LLama 8B- Instruct model is used\n",
    "\n",
    "\n",
    "Evaluate: Quality of instructions, Difficulty of instructions, Instruction SImilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca024fdb-8064-484d-9b91-c3141de8c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0392844e-2f29-4acf-9623-fb9c87d1f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "#ollama run llama3\n",
    "#Verifying if Ollama 3 is running\n",
    "import psutil\n",
    " \n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    " \n",
    "ollama_running = check_if_running(\"ollama\")\n",
    " \n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c08fb004-6982-4f70-9689-33660285e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to interact with Ollama via REST API\n",
    "\n",
    "import urllib.request\n",
    " \n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\",role=\"user\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"seed\": 123,        \n",
    "        \"temperature\": 1.,\n",
    "        \"top_p\":1,\n",
    "        \"messages\": [\n",
    "            {\"role\": role, \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    " \n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    " \n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    " \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2b87368-ec2f-4dde-9a80-a5597ea70b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are ruminant animals, which means they have a four-chambered stomach and primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as timothy or alfalfa, is a staple in many llama diets. They enjoy the sweet taste and texture of hay.\n",
      "3. Fruits and vegetables: Llamas might snack on fruits like apples, carrots, and sweet potatoes. They also enjoy leafy greens like kale, spinach, and collard greens.\n",
      "4. Grains: Some llamas may receive grains like oats, barley, or corn as part of their diet, but these should be given in moderation to avoid digestive issues.\n",
      "5. Minerals: Llamas require access to mineral supplements, such as salt, calcium, and phosphorus, which are essential for maintaining strong bones and overall health.\n",
      "\n",
      "In the wild, llamas might eat a wide variety of plants, including:\n",
      "\n",
      "* Leaves\n",
      "* Fruits\n",
      "* Bark\n",
      "* Twigs\n",
      "* Flowers\n",
      "\n",
      "However, domesticated llamas often receive a more controlled diet that is tailored to their specific needs. It's essential to provide a balanced diet and ensure they have access to fresh water at all times.\n",
      "\n",
      "Remember, every llama is unique, so it's crucial to consult with a veterinarian or experienced breeder to determine the best diet for your individual llama.\n"
     ]
    }
   ],
   "source": [
    "result = query_model(\"What do Llamas eat?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e888d9-0822-462d-8a05-537429d59c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the instructions using the prompt template proposed in the paper\n",
    "def extract_instruction(text):\n",
    "    for content in text.split(\"\\n\"):\n",
    "        if content:\n",
    "            return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0644b832-636e-4bf8-90a0-f7d3a46e94de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "query = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"\n",
    "\n",
    "result = query_model(query, role=\"assistant\")\n",
    "instruction = extract_instruction(result)\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b65cc8-31e6-41ba-b229-ba787c3e4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7ca9a-3c91-41b8-b320-489fea0ea331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
